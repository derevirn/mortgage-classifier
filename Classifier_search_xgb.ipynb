{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "X_train = pd.read_csv(\"train_values.csv\")\n",
    "y_train = pd.read_csv(\"train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {\n",
    "'msa_md': -1,\n",
    "'state_code': -1,\n",
    "'county_code': -1,\n",
    "'occupancy': 3,\n",
    "'preapproval': 3,\n",
    "'applicant_ethnicity': [3, 4, 5],\n",
    "\"applicant_race\": [6, 7, 8],\n",
    "\"applicant_sex\": [3, 4, 5]\n",
    "}\n",
    "    \n",
    "to_log = [\"loan_amount\", \"applicant_income\", \"number_of_owner-occupied_units\",\n",
    "          \"number_of_1_to_4_family_units\", \"minority_population\"]\n",
    "\n",
    "to_drop = [\"row_id\", \"number_of_1_to_4_family_units\",\n",
    "           \"occupancy\", \"county_code\", \"preapproval\"]\n",
    "\n",
    "num_cols = [\"loan_amount\", \"applicant_income\", \"population\", \"minority_population_pct\",\n",
    "            \"ffiecmedian_family_income\", \"tract_to_msa_md_income_pct\",\n",
    "            \"number_of_owner-occupied_units\"]\n",
    "\n",
    "cat_cols_few = [\"loan_type\", \"property_type\", \"loan_purpose\",\n",
    "            \"applicant_ethnicity\", \"applicant_race\",\n",
    "            \"applicant_sex\", \"co_applicant\"]\n",
    "\n",
    "def prepare_data(df):\n",
    "    \n",
    "    df[\"co_applicant\"] = df[\"co_applicant\"].astype(\"int8\")\n",
    "    \n",
    "    df.replace(replace_dict, np.nan, inplace = True)\n",
    "    \n",
    "    for col in num_cols:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "        \n",
    "    for col in cat_cols_few:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "          \n",
    "    df[\"minority_population\"] = (df[\"minority_population_pct\"] / 100) * (df[\"population\"])\n",
    "    df[\"tract_family_income\"] = (df[\"tract_to_msa_md_income_pct\"] / 100) * (df[\"ffiecmedian_family_income\"])\n",
    "\n",
    "    df[to_log] = df[to_log].applymap(math.log)\n",
    "    \n",
    "    to_drop.extend([\"minority_population_pct\", \"population\",\n",
    "                    \"ffiecmedian_family_income\", \"tract_to_msa_md_income_pct\"])\n",
    "    df.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    df = pd.get_dummies(df, columns = cat_cols_few)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 29 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   loan_amount                     500000 non-null  float64\n",
      " 1   msa_md                          500000 non-null  float64\n",
      " 2   state_code                      500000 non-null  float64\n",
      " 3   applicant_income                500000 non-null  float64\n",
      " 4   number_of_owner-occupied_units  500000 non-null  float64\n",
      " 5   lender                          500000 non-null  float64\n",
      " 6   minority_population             500000 non-null  float64\n",
      " 7   tract_family_income             500000 non-null  float64\n",
      " 8   loan_type_1                     500000 non-null  uint8  \n",
      " 9   loan_type_2                     500000 non-null  uint8  \n",
      " 10  loan_type_3                     500000 non-null  uint8  \n",
      " 11  loan_type_4                     500000 non-null  uint8  \n",
      " 12  property_type_1                 500000 non-null  uint8  \n",
      " 13  property_type_2                 500000 non-null  uint8  \n",
      " 14  property_type_3                 500000 non-null  uint8  \n",
      " 15  loan_purpose_1                  500000 non-null  uint8  \n",
      " 16  loan_purpose_2                  500000 non-null  uint8  \n",
      " 17  loan_purpose_3                  500000 non-null  uint8  \n",
      " 18  applicant_ethnicity_1.0         500000 non-null  uint8  \n",
      " 19  applicant_ethnicity_2.0         500000 non-null  uint8  \n",
      " 20  applicant_race_1.0              500000 non-null  uint8  \n",
      " 21  applicant_race_2.0              500000 non-null  uint8  \n",
      " 22  applicant_race_3.0              500000 non-null  uint8  \n",
      " 23  applicant_race_4.0              500000 non-null  uint8  \n",
      " 24  applicant_race_5.0              500000 non-null  uint8  \n",
      " 25  applicant_sex_1.0               500000 non-null  uint8  \n",
      " 26  applicant_sex_2.0               500000 non-null  uint8  \n",
      " 27  co_applicant_0                  500000 non-null  uint8  \n",
      " 28  co_applicant_1                  500000 non-null  uint8  \n",
      "dtypes: float64(8), uint8(21)\n",
      "memory usage: 40.5 MB\n"
     ]
    }
   ],
   "source": [
    "X_train = prepare_data(X_train)\n",
    "\n",
    "ce_target = ce.TargetEncoder(cols = [\"lender\", \"msa_md\", \"state_code\"], smoothing = 5, return_df = True)\n",
    "X_train = ce_target.fit_transform(X_train, y_train[\"accepted\"])\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.values\n",
    "y = y_train[\"accepted\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'max_depth': [5, 6, 7, 8],\n",
    "        'n_estimators': [200, 300, 400, 500, 600],\n",
    "        'reg_alpha': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "        'subsample': [0.6, 0.7, 0.8, 1],\n",
    "        'colsample_bytree': [0.6, 0.8, 1],\n",
    "        'min_child_weight': [1, 4, 5, 6, 8],\n",
    "        'learning_rate': [0.01, 0.02, 0.1]\n",
    "    \n",
    "        }\n",
    "\n",
    "model = XGBClassifier(objective = 'binary:logistic', silent=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed: 31.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x000002688E1035C8>,\n",
       "                   error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=-1, nthread=None,\n",
       "                                           objective='binary...\n",
       "                   iid='deprecated', n_iter=5, n_jobs=4,\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.8, 1],\n",
       "                                        'learning_rate': [0.01, 0.02, 0.1],\n",
       "                                        'max_depth': [5, 6, 7, 8],\n",
       "                                        'min_child_weight': [1, 4, 5, 6, 8],\n",
       "                                        'n_estimators': [200, 300, 400, 500,\n",
       "                                                         600],\n",
       "                                        'reg_alpha': [0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'subsample': [0.6, 0.7, 0.8, 1]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=True, scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = 5\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "cv = skf.split(X, y)\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=params, n_iter=param_comb, return_train_score=True,\n",
    "                                   scoring='accuracy', n_jobs=4, cv=cv, verbose=3)\n",
    "\n",
    "random_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.8, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "              min_child_weight=5, missing=None, n_estimators=500, n_jobs=-1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0.1, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=True, subsample=0.7, verbosity=1)\n",
      "\n",
      " Best score for 5-fold search with 5 parameter combinations:\n",
      "0.7261019999999999\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 0.7, 'reg_alpha': 0.1, 'n_estimators': 500, 'min_child_weight': 5, 'max_depth': 7, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_reg_alpha</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>286.502708</td>\n",
       "      <td>2.516713</td>\n",
       "      <td>1.332300</td>\n",
       "      <td>0.088961</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'subsample': 0.7, 'reg_alpha': 0.1, 'n_estima...</td>\n",
       "      <td>0.72759</td>\n",
       "      <td>0.72337</td>\n",
       "      <td>0.72748</td>\n",
       "      <td>0.72748</td>\n",
       "      <td>0.72459</td>\n",
       "      <td>0.726102</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754683</td>\n",
       "      <td>0.754715</td>\n",
       "      <td>0.754472</td>\n",
       "      <td>0.754495</td>\n",
       "      <td>0.755755</td>\n",
       "      <td>0.754824</td>\n",
       "      <td>0.000475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>346.089515</td>\n",
       "      <td>6.044303</td>\n",
       "      <td>1.787042</td>\n",
       "      <td>0.133804</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>600</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'subsample': 0.8, 'reg_alpha': 0.1, 'n_estima...</td>\n",
       "      <td>0.72765</td>\n",
       "      <td>0.72330</td>\n",
       "      <td>0.72713</td>\n",
       "      <td>0.72690</td>\n",
       "      <td>0.72436</td>\n",
       "      <td>0.725868</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>2</td>\n",
       "      <td>0.733393</td>\n",
       "      <td>0.734565</td>\n",
       "      <td>0.733888</td>\n",
       "      <td>0.734003</td>\n",
       "      <td>0.734542</td>\n",
       "      <td>0.734078</td>\n",
       "      <td>0.000439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>318.330126</td>\n",
       "      <td>7.843158</td>\n",
       "      <td>1.362510</td>\n",
       "      <td>0.172356</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>{'subsample': 0.7, 'reg_alpha': 0, 'n_estimato...</td>\n",
       "      <td>0.72789</td>\n",
       "      <td>0.72360</td>\n",
       "      <td>0.72687</td>\n",
       "      <td>0.72640</td>\n",
       "      <td>0.72374</td>\n",
       "      <td>0.725700</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>3</td>\n",
       "      <td>0.733785</td>\n",
       "      <td>0.735060</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.734348</td>\n",
       "      <td>0.734955</td>\n",
       "      <td>0.734505</td>\n",
       "      <td>0.000463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210.022114</td>\n",
       "      <td>38.634568</td>\n",
       "      <td>0.767775</td>\n",
       "      <td>0.106037</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>{'subsample': 0.7, 'reg_alpha': 0.1, 'n_estima...</td>\n",
       "      <td>0.72647</td>\n",
       "      <td>0.72205</td>\n",
       "      <td>0.72544</td>\n",
       "      <td>0.72537</td>\n",
       "      <td>0.72302</td>\n",
       "      <td>0.724470</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>4</td>\n",
       "      <td>0.731550</td>\n",
       "      <td>0.732525</td>\n",
       "      <td>0.731220</td>\n",
       "      <td>0.731540</td>\n",
       "      <td>0.732005</td>\n",
       "      <td>0.731768</td>\n",
       "      <td>0.000454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>245.384254</td>\n",
       "      <td>4.176276</td>\n",
       "      <td>0.849997</td>\n",
       "      <td>0.059375</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'subsample': 0.8, 'reg_alpha': 0.3, 'n_estima...</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>0.71531</td>\n",
       "      <td>0.71903</td>\n",
       "      <td>0.71906</td>\n",
       "      <td>0.71541</td>\n",
       "      <td>0.717762</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>5</td>\n",
       "      <td>0.718845</td>\n",
       "      <td>0.720178</td>\n",
       "      <td>0.719135</td>\n",
       "      <td>0.719065</td>\n",
       "      <td>0.719993</td>\n",
       "      <td>0.719443</td>\n",
       "      <td>0.000536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2     286.502708      2.516713         1.332300        0.088961   \n",
       "0     346.089515      6.044303         1.787042        0.133804   \n",
       "3     318.330126      7.843158         1.362510        0.172356   \n",
       "4     210.022114     38.634568         0.767775        0.106037   \n",
       "1     245.384254      4.176276         0.849997        0.059375   \n",
       "\n",
       "  param_subsample param_reg_alpha param_n_estimators param_min_child_weight  \\\n",
       "2             0.7             0.1                500                      5   \n",
       "0             0.8             0.1                600                      4   \n",
       "3             0.7               0                400                      8   \n",
       "4             0.7             0.1                300                      6   \n",
       "1             0.8             0.3                500                      6   \n",
       "\n",
       "  param_max_depth param_learning_rate param_colsample_bytree  \\\n",
       "2               7                 0.1                    0.8   \n",
       "0               7                0.02                    0.8   \n",
       "3               8                0.02                      1   \n",
       "4               8                0.02                      1   \n",
       "1               5                0.01                      1   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "2  {'subsample': 0.7, 'reg_alpha': 0.1, 'n_estima...            0.72759   \n",
       "0  {'subsample': 0.8, 'reg_alpha': 0.1, 'n_estima...            0.72765   \n",
       "3  {'subsample': 0.7, 'reg_alpha': 0, 'n_estimato...            0.72789   \n",
       "4  {'subsample': 0.7, 'reg_alpha': 0.1, 'n_estima...            0.72647   \n",
       "1  {'subsample': 0.8, 'reg_alpha': 0.3, 'n_estima...            0.72000   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "2            0.72337            0.72748            0.72748            0.72459   \n",
       "0            0.72330            0.72713            0.72690            0.72436   \n",
       "3            0.72360            0.72687            0.72640            0.72374   \n",
       "4            0.72205            0.72544            0.72537            0.72302   \n",
       "1            0.71531            0.71903            0.71906            0.71541   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "2         0.726102        0.001775                1            0.754683   \n",
       "0         0.725868        0.001715                2            0.733393   \n",
       "3         0.725700        0.001727                3            0.733785   \n",
       "4         0.724470        0.001656                4            0.731550   \n",
       "1         0.717762        0.001992                5            0.718845   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "2            0.754715            0.754472            0.754495   \n",
       "0            0.734565            0.733888            0.734003   \n",
       "3            0.735060            0.734375            0.734348   \n",
       "4            0.732525            0.731220            0.731540   \n",
       "1            0.720178            0.719135            0.719065   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "2            0.755755          0.754824         0.000475  \n",
       "0            0.734542          0.734078         0.000439  \n",
       "3            0.734955          0.734505         0.000463  \n",
       "4            0.732005          0.731768         0.000454  \n",
       "1            0.719993          0.719443         0.000536  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ )\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "results.sort_values(\"rank_test_score\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
